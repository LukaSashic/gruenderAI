"""
GrÃ¼nderAI Pure Python IRT Engine
No external scientific libraries required - uses only Python standard library
Implements Howard's 7-dimension framework with business context adaptation
"""

import math
import json
import uuid
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timedelta

class GruenderAIEngine:
    """
    Main assessment engine for GrÃ¼nderAI
    Implements IRT-CAT with business context adaptation
    """
    
    def __init__(self):
        # Assessment configuration
        self.max_items = 18
        self.min_items = 12  
        self.target_se = 0.20
        self.max_time_minutes = 15
        
        # Session storage (in production, this would be in database)
        self.sessions = {}
        
        print("ðŸ§  GrÃ¼nderAI Assessment Engine initialized")
        print(f"   Max items: {self.max_items}")
        print(f"   Target precision: SE < {self.target_se}")
        print(f"   Time limit: {self.max_time_minutes} minutes")
    
    def grm_probability(self, theta: float, discrimination: float, 
                       difficulty_thresholds: List[float], category: int) -> float:
        """
        Graded Response Model probability calculation
        
        Args:
            theta: Person's trait level (-3 to +3, 0 = average)
            discrimination: How well item distinguishes people (higher = better)
            difficulty_thresholds: Item difficulty levels for each response category
            category: Response category (1-5 for Likert scale)
        
        Returns:
            Probability of selecting this category (0.0 to 1.0)
        """
        try:
            # Logistic function with overflow protection
            def safe_logistic(x):
                if x > 500: return 1.0
                elif x < -500: return 0.0
                else: return 1 / (1 + math.exp(-x))
            
            if category == 1:  # "Strongly disagree"
                z = discrimination * (theta - difficulty_thresholds[0])
                return safe_logistic(-z)
            elif category == 5:  # "Strongly agree"  
                z = discrimination * (theta - difficulty_thresholds[-1])
                return safe_logistic(z)
            else:  # Middle categories (2, 3, 4)
                z1 = discrimination * (theta - difficulty_thresholds[category-2])
                z2 = discrimination * (theta - difficulty_thresholds[category-1])
                p1 = safe_logistic(z1)
                p2 = safe_logistic(z2)
                return max(0.001, p1 - p2)  # Ensure positive probability
                
        except (IndexError, OverflowError):
            return 0.001  # Fallback probability

    def fisher_information(self, theta: float, discrimination: float, 
                          difficulty_thresholds: List[float]) -> float:
        """
        Calculate Fisher Information - measures how much information
        this item provides about a person's trait level
        
        Higher information = better measurement precision
        """
        total_info = 0.0
        
        for category in range(1, 6):  # 5-point Likert scale
            prob = self.grm_probability(theta, discrimination, difficulty_thresholds, category)
            if prob > 0.001:
                # Fisher Information formula for categorical responses
                total_info += (discrimination ** 2) * prob * (1 - prob)
        
        return max(total_info, 0.001)  # Ensure positive information

    def estimate_theta(self, responses: List[int], items: List[Dict]) -> Tuple[float, float]:
        """
        Estimate person's trait level using Maximum Likelihood
        
        Returns:
            (theta_estimate, standard_error)
        """
        if not responses or not items:
            return 0.0, 1.0  # Neutral with high uncertainty
        
        # Grid search for maximum likelihood (simple but effective)
        best_theta = 0.0
        best_likelihood = -999999
        
        # Test theta values from -3 to +3 (covers 99.7% of population)
        for theta_test in [i * 0.1 for i in range(-30, 31)]:
            log_likelihood = 0.0
            
            # Calculate likelihood for this theta
            for response, item in zip(responses, items):
                prob = self.grm_probability(
                    theta_test,
                    item['discrimination'],
                    item['difficulty_thresholds'],
                    response
                )
                if prob > 0.001:
                    log_likelihood += math.log(prob)
                else:
                    log_likelihood += math.log(0.001)  # Penalty for impossible responses
            
            # Keep track of best theta
            if log_likelihood > best_likelihood:
                best_likelihood = log_likelihood
                best_theta = theta_test
        
        # Calculate standard error from Fisher Information
        total_info = sum(
            self.fisher_information(best_theta, item['discrimination'], item['difficulty_thresholds'])
            for item in items
        )
        
        standard_error = 1.0 / math.sqrt(max(total_info, 0.1))
        standard_error = min(2.0, max(0.1, standard_error))  # Reasonable bounds
        
        return best_theta, standard_error

    def select_next_item(self, current_theta: float, available_items: List[Dict], 
                        used_items: List[str] = None) -> Optional[Dict]:
        """
        Select item that provides maximum information for current theta estimate
        This is the 'adaptive' part of Computerized Adaptive Testing
        """
        if not available_items:
            return None
        
        used_set = set(used_items or [])
        candidates = [item for item in available_items if item.get('item_id') not in used_set]
        
        if not candidates:
            return None
        
        best_item = None
        max_info = -1
        
        for item in candidates:
            info = self.fisher_information(
                current_theta,
                item['discrimination'],
                item['difficulty_thresholds']
            )
            
            if info > max_info:
                max_info = info
                best_item = item
        
        return best_item

# Test the engine
if __name__ == "__main__":
    print("ðŸ§ª Testing GrÃ¼nderAI Engine...")
    
    engine = GruenderAIEngine()
    
    # Test basic probability calculation
    prob = engine.grm_probability(0.5, 1.8, [-1.0, -0.2, 0.5, 1.2], 3)
    print(f"âœ… Probability calculation: {prob:.3f}")
    
    # Test Fisher Information
    info = engine.fisher_information(0.5, 1.8, [-1.0, -0.2, 0.5, 1.2])
    print(f"âœ… Fisher Information: {info:.3f}")
    
    print("ðŸš€ GrÃ¼nderAI Engine is working perfectly!")